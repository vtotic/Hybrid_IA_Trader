import pandas as pd
import numpy as np
import os
import joblib
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

def fetch_data_from_csv(csv_path):
    """Fetches historical data from an exported MT5 CSV file"""
    if not os.path.exists(csv_path):
        print(f"Error: CSV file not found at {csv_path}")
        print("Please export the history from MT5 (Ctrl+S on the chart) and save it here.")
        return None
    
    print(f"Loading data from {csv_path}...")
    
    names = ['time', 'open', 'high', 'low', 'close', 'volume', 'spread']
    
    try:
        # Probamos primero el formato detectado: Comas + UTF-16
        df = pd.read_csv(csv_path, sep=',', names=names, header=None, encoding='utf-16')
        
        # Si por alguna razón se cargaron más columnas o falló, probamos tabulación
        if df['open'].isna().all():
            df = pd.read_csv(csv_path, sep='\t', names=names, header=None, encoding='utf-16')
            
        # Limpieza de nulos y parseo de tiempo
        df['time'] = pd.to_datetime(df['time'], format='%Y.%m.%d %H:%M', errors='coerce')
        df = df.dropna(subset=['time', 'close']) # Eliminar filas mal parseadas
        
        return df
    except Exception as e1:
        print(f"Error parseando con UTF-16: {e1}")
        try:
            # Fallback a UTF-8 estándar
            df = pd.read_csv(csv_path, sep=',', names=names, header=None)
            df['time'] = pd.to_datetime(df['time'], errors='coerce')
            return df.dropna(subset=['time'])
        except Exception as e2:
            print(f"Error fatal: {e2}")
            return None

def calc_ema(series, period):
    return series.ewm(span=period, adjust=False).mean()

def calc_atr(df, period=14):
    high_low = df['high'] - df['low']
    high_close = np.abs(df['high'] - df['close'].shift())
    low_close = np.abs(df['low'] - df['close'].shift())
    ranges = pd.concat([high_low, high_close, low_close], axis=1)
    true_range = np.max(ranges, axis=1)
    return true_range.rolling(period).mean()
    
def calc_adx(df, period=14):
    plus_dm = df['high'].diff()
    minus_dm = df['low'].diff(-1) * -1
    
    plus_dm[plus_dm < 0] = 0
    plus_dm[plus_dm < minus_dm] = 0
    
    minus_dm[minus_dm < 0] = 0
    minus_dm[minus_dm < plus_dm] = 0
    
    tr = calc_atr(df, 1)
    
    atr_smooth = tr.ewm(alpha=1/period, adjust=False).mean()
    plus_di = 100 * (plus_dm.ewm(alpha=1/period, adjust=False).mean() / atr_smooth)
    minus_di = 100 * (minus_dm.ewm(alpha=1/period, adjust=False).mean() / atr_smooth)
    
    dx = (np.abs(plus_di - minus_di) / np.abs(plus_di + minus_di)) * 100
    adx = dx.ewm(alpha=1/period, adjust=False).mean()
    return adx

def feature_engineering(df):
    """
    Calculates the exact features the EA sends:
    1. atr (14)
    2. adx (14)
    3. spread
    4. ema_slope (EMA200 prev - EMA200 current)
    5. volume (tick_volume)
    6. hour
    """
    # ATR (14)
    df['atr'] = calc_atr(df, 14)
    
    # ADX (14)
    df['adx'] = calc_adx(df, 14)
    
    # Calculate EMA 200 for slope
    ema200 = calc_ema(df['close'], 200)
    # EMA Slope: previous (shift 1) - current
    df['ema_slope'] = ema200.shift(1) - ema200
    
    # Los nombres ya coinciden con lo que espera el EA
    df['spread'] = df['spread']
    df['volume'] = df['volume']
    df['hour'] = df['time'].dt.hour
    
    # Target Creation (Labeling)
    lookahead = 3 # Look 3 bars into the future
    df['future_return'] = df['close'].shift(-lookahead) - df['close']
    
    # We label a setup as 1 (Good setup/High Probability) if the absolute return 
    # over the next 3 bars is greater than 1.5x the current ATR. 
    df['target'] = np.where(abs(df['future_return']) > (df['atr'] * 1.5), 1, 0)
    
    # Drop NaNs generated by indicators and shifts
    df.dropna(inplace=True)
    return df

def train_model(csv_path="history.csv", model_name="model"):
    print(f"\n--- Starting Training for {model_name.upper()} ---")
    df = fetch_data_from_csv(csv_path)
    
    if df is None:
        return
        
    df = feature_engineering(df)
    
    # The features sent by EA's FeatureExtractor()
    features = ['atr', 'adx', 'spread', 'ema_slope', 'volume', 'hour']
    X = df[features]
    y = df['target']
    
    print(f"Data shape after feature engineering: {X.shape}")
    print(f"Target distribution (0=Fail, 1=Success): \n{y.value_counts(normalize=True)*100}")
    
    # Split data chronologically (80% train, 20% test)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    
    print("Training XGBoost Classifier...")
    model = XGBClassifier(
        n_estimators=100,
        learning_rate=0.05,
        max_depth=4,
        random_state=42,
        eval_metric='logloss'
    )
    
    model.fit(X_train, y_train)
    
    # Evaluation
    preds = model.predict(X_test)
    print("\nModel Evaluation:")
    print(f"Accuracy: {accuracy_score(y_test, preds)*100:.2f}%")
    print("\nClassification Report:")
    print(classification_report(y_test, preds))
    
    # Save the model
    os.makedirs('models', exist_ok=True)
    model_path = f'models/{model_name}_model.pkl'
    joblib.dump(model, model_path)
    print(f"Model successfully saved to {model_path}")

if __name__ == "__main__":
    print("====================================")
    print(" HYBRID EA - AI TRAINING PIPELINE")
    print("====================================")
    
    # Export your data from MT5 on Mac (Parallels/Wine):
    # Go to View -> Symbols -> Bars -> Select US100/NAS100, Timeframe -> Export
    # Save as 'history_m15.csv' for the Swing model and 'history_m5.csv' for Scalping model
    # in this exact folder (AI_Engine).
    
    # 1. Train Swing Model (Higher Timeframe, e.g., M15) - Trend Following
    try:
        train_model(csv_path="history_m15.csv", model_name="swing")
    except Exception as e:
        print(f"Error training Swing model: {e}")
        
    # 2. Train Scalping Model (Lower Timeframe, e.g., M5) - Mean Reversion
    try:
        train_model(csv_path="history_m5.csv", model_name="scalping")
    except Exception as e:
        print(f"Error training Scalping model: {e}")
        
    print("\nTraining Process Complete! You can now start the API server using: uvicorn api:app --host 127.0.0.1 --port 5000")
